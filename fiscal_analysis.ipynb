{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fiscal Report Analysis\n",
    "\n",
    "This notebook demonstrates how to load a PDF, chunk the text, generate embeddings, and use a custom retriever to answer questions about the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Getting Started\n",
    "\n",
    "First, we'll install the necessary Python packages for our project. We've added `PyYAML` and `mermaid-py` to help visualize our agent configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install airefinery-sdk python-dotenv numpy pdfplumber PyYAML mermaid-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Setting Up the Environment\n",
    "\n",
    "Here, we import all the required libraries and functions. We also load environment variables, which securely store sensitive information like API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import getpass\n",
    "import yaml\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv, find_dotenv, set_key\n",
    "from IPython.display import display, Markdown, Code\n",
    "from air import AIRefinery, DistillerClient, login\n",
    "from air.utils import async_print\n",
    "from library.data_processing import extract_text_with_pdfplumber, extract_tables_with_pdfplumber, chunk_text, generate_document_embeddings, cache_embeddings, load_cached_embeddings\n",
    "from library.vector_store import InMemoryVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Securely Load Credentials\n",
    "\n",
    "We'll check if your AI Refinery credentials are saved in a `.env` file. If not, you'll be prompted to enter them, and we'll save them for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "env_path = find_dotenv()\n",
    "if not env_path:\n",
    "    with open(\".env\", \"w\") as f:\n",
    "        pass\n",
    "    env_path = find_dotenv()\n",
    "\n",
    "account = os.getenv(\"ACCOUNT\")\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "if not account:\n",
    "    account = getpass.getpass(\"Enter your AI Refinery Account ID: \")\n",
    "    set_key(env_path, \"ACCOUNT\", account)\n",
    "\n",
    "if not api_key:\n",
    "    api_key = getpass.getpass(\"Enter your AI Refinery API Key: \")\n",
    "    set_key(env_path, \"API_KEY\", api_key)\n",
    "\n",
    "load_dotenv(override=True)\n",
    "print(\"Credentials loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Processing the Document\n",
    "\n",
    "We take a PDF fiscal report, read its text and tables, and break it down into smaller, more manageable chunks. We then convert these chunks into a numerical format (called embeddings) that our AI can understand. This process is saved (cached) so we don't have to repeat it every time we run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS_CACHE_PATH = \"embeddings.pickle\"\n",
    "PDF_PATH = \"data/acn-third-quarter-fiscal-2025-earnings-release.pdf\"\n",
    "\n",
    "auth = login(\n",
    "    account=str(os.getenv(\"ACCOUNT\")),\n",
    "    api_key=str(os.getenv(\"API_KEY\")),\n",
    ")\n",
    "base_url = os.getenv(\"AIREFINERY_ADDRESS\", \"\")\n",
    "air_client = AIRefinery(**auth.openai(base_url=base_url))\n",
    "embedding_client = air_client.embeddings\n",
    "\n",
    "if os.path.exists(EMBEDDINGS_CACHE_PATH):\n",
    "    cached_data = load_cached_embeddings(EMBEDDINGS_CACHE_PATH)\n",
    "    documents_from_pdf = cached_data[\"documents\"]\n",
    "    document_vectors = cached_data[\"vectors\"]\n",
    "else:\n",
    "    # Extract both text and tables using pdfplumber for better results\n",
    "    plain_text = extract_text_with_pdfplumber(PDF_PATH)\n",
    "    table_html = extract_tables_with_pdfplumber(PDF_PATH)\n",
    "    combined_content = plain_text + \"\\n\\n--- Extracted Tables ---\\n\" + table_html\n",
    "    \n",
    "    documents_from_pdf = chunk_text(combined_content)\n",
    "    document_vectors = generate_document_embeddings(documents_from_pdf, embedding_client)\n",
    "    if documents_from_pdf and document_vectors:\n",
    "        cache_embeddings(documents_from_pdf, document_vectors, EMBEDDINGS_CACHE_PATH)\n",
    "\n",
    "vector_store = InMemoryVectorStore(documents_from_pdf, document_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Why Do We Chunk Documents?\n",
    "\n",
    "Large Language Models (LLMs) have a limited context window, meaning they can only process a certain amount of text at once. To work with large documents, we break them into smaller, overlapping 'chunks.' This ensures that the model has enough context to find relevant information without being overwhelmed. Below, you can see the first few chunks created from our document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    chunk_id = f\"chunk_{i}\"\n",
    "    if chunk_id in documents_from_pdf:\n",
    "        print(f\"--- {chunk_id.upper()} ---\")\n",
    "        print(documents_from_pdf[chunk_id]['text'])\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Creating a Custom Search Tool\n",
    "\n",
    "This step defines our specialized search function. When we ask a question, this tool converts the question into the same numerical format as our document chunks. It then searches through the chunks to find the most relevant pieces of information to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _format_document_result(doc_id, doc, source_weight=1, retriever_name=\"\"):\n",
    "    base_score = doc.get(\"score\", 0.0)\n",
    "    final_score = float(base_score * source_weight)\n",
    "    content_text = doc.get(\"content\", {}).get(\"text\", \"\")\n",
    "    formatted_result = f\"Source: {retriever_name}\\nID: {doc_id}\\nContent: {content_text[:500]}...\"\n",
    "    return {\"result\": formatted_result, \"score\": final_score}\n",
    "\n",
    "async def custom_in_memory_vector_search(query: str):\n",
    "    print(f\"Received query for vector search: '{query}'\")\n",
    "    response = embedding_client.create(\n",
    "        input=[query],\n",
    "        model=\"nvidia/nv-embedqa-mistral-7b-v2\",\n",
    "        encoding_format=\"float\",\n",
    "        extra_body={\"input_type\": \"query\", \"truncate\": \"NONE\"},\n",
    "    )\n",
    "    query_vector = np.array(response.data[0].embedding, dtype=np.float32).reshape(1, -1)\n",
    "    \n",
    "    print(\"Searching for relevant documents in the vector store...\")\n",
    "    documents = vector_store.search(query_vector)\n",
    "\n",
    "    if not documents:\n",
    "        return [{\"result\": \"There is no relevant document from the PDF.\", \"score\": 0}]\n",
    "\n",
    "    results = [\n",
    "        _format_document_result(\n",
    "            doc[\"id\"], doc, source_weight=1, retriever_name=\"PDF-NumPy-Retriever\"\n",
    "        )\n",
    "        for doc in documents\n",
    "    ]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Initialize the Research Agent\n",
    "\n",
    "Now, we set up the first AI agent that will use our custom search tool. We create a project for simple questions (`DocumentSearch`). This setup only needs to be run once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distiller_client = DistillerClient(base_url=base_url)\n",
    "uuid = os.getenv(\"UUID\", \"test_user_refactored\")\n",
    "research_config_path = \"custom_vector_search.yaml\"\n",
    "\n",
    "# Create project for the simple Research Agent\n",
    "research_project = \"DocumentSearch\"\n",
    "distiller_client.create_project(\n",
    "    config_path=research_config_path, project=research_project\n",
    ")\n",
    "\n",
    "# Define the executor dictionary for the agent\n",
    "research_executor_dict = {\n",
    "    \"Research Agent\": {\n",
    "        \"Fiscal Reports Database\": custom_in_memory_vector_search,\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Research Agent project created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Visualize the Research Agent Workflow\n",
    "\n",
    "Here we can see a simple diagram of our Research Agent. The `Distiller Orchestrator` takes our query and passes it to the `Research Agent`, which uses the `Fiscal Reports Database` tool to find an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(research_config_path, 'r') as f:\n",
    "    config_data = yaml.safe_load(f)\n",
    "\n",
    "orchestrator_name = \"Distiller Orchestrator\"\n",
    "agent_name = config_data.get('utility_agents', [{}])[0].get('agent_name', 'Research Agent')\n",
    "tool_name = config_data.get('utility_agents', [{}])[0].get('config', {}).get('tools', [{}])[0].get('tool_name', 'Tool')\n",
    "\n",
    "mermaid_code = f\"\"\"graph TD\n",
    "    A[User Query] --> O(({orchestrator_name}));\n",
    "    O --> B[{agent_name}];\n",
    "    B --> C{{{{{tool_name}}}}};\n",
    "\"\"\"\n",
    "display(Markdown(\"```mermaid\\n\" + mermaid_code + \"\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Asking a Simple Question\n",
    "\n",
    "We can now use our 'Research Agent' to ask a specific question. The agent uses our custom search tool to find the answer in the document. **You can change the `query` text in the cell below and rerun it to ask a new question.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def ask_simple_question(query: str):\n",
    "    \"\"\"Runs a query using the Research Agent.\"\"\"\n",
    "    async with distiller_client(\n",
    "        project=research_project,\n",
    "        uuid=uuid,\n",
    "        executor_dict=research_executor_dict,\n",
    "    ) as dc:\n",
    "        print(f\"----\\nQuery: {query}\")\n",
    "        responses = await dc.query(query=query)\n",
    "        async for response in responses:\n",
    "            await async_print(f\"Response: {response['content']}\")\n",
    "\n",
    "# Define your query here\n",
    "simple_query = \"how much generative ai bookings were there?\"\n",
    "await ask_simple_question(simple_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Initialize the Flow Super Agent\n",
    "\n",
    "For more complex questions, we'll set up a more advanced 'Flow Super Agent'. This agent can perform multi-step reasoning to provide a comprehensive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_config_path = \"flow_super_agent.yaml\"\n",
    "\n",
    "# Create project for the Flow Super Agent\n",
    "flow_project = \"FinancialAnalysisFlow\"\n",
    "distiller_client.create_project(\n",
    "    config_path=flow_config_path, project=flow_project\n",
    ")\n",
    "\n",
    "# Define the executor dictionary for the agent\n",
    "flow_executor_dict = {\n",
    "    \"Fiscal Report Researcher\": {\n",
    "        \"Fiscal Reports Database\": custom_in_memory_vector_search,\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Flow Super Agent project created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Visualize the Flow Super Agent Workflow\n",
    "\n",
    "This diagram shows the more complex workflow of our `FlowSuperAgent`. The `Distiller Orchestrator` initiates the `FlowSuperAgent`, which in turn orchestrates multiple specialized agents to build a final, comprehensive answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(flow_config_path, 'r') as f:\n",
    "    config_data = yaml.safe_load(f)\n",
    "\n",
    "orchestrator_name = \"Distiller Orchestrator\"\n",
    "super_agent_config = config_data.get('super_agents', [{}])[0]\n",
    "super_agent_name = super_agent_config.get('agent_name', 'Super Agent')\n",
    "agent_flow = super_agent_config.get('config', {}).get('agent_list', [])\n",
    "entry_agent = agent_flow[0]['agent_name'] if agent_flow else ''\n",
    "\n",
    "mermaid_lines = [\"graph TD\"]\n",
    "mermaid_lines.append(f\"    O(({orchestrator_name})) --> S[{super_agent_name}]\")\n",
    "mermaid_lines.append(f\"    subgraph {super_agent_name}\")\n",
    "mermaid_lines.append(\"        direction LR\")\n",
    "\n",
    "for agent_step in agent_flow:\n",
    "    from_agent = agent_step['agent_name']\n",
    "    if 'next_step' in agent_step:\n",
    "        for to_agent in agent_step['next_step']:\n",
    "            mermaid_lines.append(f\"        {from_agent.replace(' ', '_')}[{from_agent}] --> {to_agent.replace(' ', '_')}[{to_agent}]\")\n",
    "    else:\n",
    "        mermaid_lines.append(f\"        {from_agent.replace(' ', '_')}[{from_agent}]\")\n",
    "\n",
    "mermaid_lines.append(\"    end\")\n",
    "mermaid_code = \"\\n\".join(mermaid_lines)\n",
    "\n",
    "display(Markdown(\"```mermaid\\n\" + mermaid_code + \"\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12: Performing a Deeper Analysis\n",
    "\n",
    "Now we can use the 'Flow Super Agent' for questions that require reasoning and combining information. **You can change the `query` text in the cell below and rerun it to request a new analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def perform_comparative_analysis(query: str):\n",
    "    \"\"\"Runs a query using the Flow Super Agent.\"\"\"\n",
    "    async with distiller_client(\n",
    "        project=flow_project,\n",
    "        uuid=uuid,\n",
    "        executor_dict=flow_executor_dict,\n",
    "    ) as dc:\n",
    "        print(f\"----\\nQuery: {query}\")\n",
    "        responses = await dc.query(query=query)\n",
    "        async for response in responses:\n",
    "            await async_print(f\"Role: {response.get('role', 'System')}\\nContent: {response.get('content', '')}\\n\")\n",
    "\n",
    "# Define your query here\n",
    "analysis_query = \"Provide a comparative analysis of the attached fiscal report.\"\n",
    "await perform_comparative_analysis(analysis_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
